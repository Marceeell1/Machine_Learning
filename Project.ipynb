{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e7403b86",
      "metadata": {
        "id": "e7403b86"
      },
      "source": [
        "# Project : German Credit Risk Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4b4c9c7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b4c9c7c",
        "outputId": "1c3ef45c-c6ec-41bb-caca-9e48b8345a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ucimlrepo in c:\\users\\liuja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\liuja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ucimlrepo) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\liuja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ucimlrepo) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\liuja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\liuja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\liuja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\liuja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\liuja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0 -> 25.3\n",
            "[notice] To update, run: C:\\Users\\liuja\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install ucimlrepo if it is not already installed\n",
        "%pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79a9cea9",
      "metadata": {
        "id": "79a9cea9"
      },
      "source": [
        "### Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b5811766",
      "metadata": {
        "id": "b5811766"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eddc5c5d",
      "metadata": {
        "id": "eddc5c5d"
      },
      "source": [
        "### Gather and Structure the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "28197f3f",
      "metadata": {
        "id": "28197f3f"
      },
      "outputs": [],
      "source": [
        "# Load dataset (German Credit Data from UCI)\n",
        "statlog_data = fetch_ucirepo(id=144)\n",
        "X = statlog_data.data.features\n",
        "y = statlog_data.data.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "de0d231b",
      "metadata": {
        "id": "de0d231b"
      },
      "outputs": [],
      "source": [
        "# Rename columns based on UCI documentation\n",
        "X.columns = [\n",
        "    \"Status_checking_account\", \"Duration_month\", \"Credit_history\", \"Purpose\",\n",
        "    \"Credit_amount\", \"Savings_account\", \"Employment_since\", \"Installment_rate\",\n",
        "    \"Personal_status_sex\", \"Other_debtors_guarantors\", \"Residence_since\",\n",
        "    \"Property\", \"Age_years\", \"Other_installment_plans\", \"Housing\",\n",
        "    \"Existing_credits\", \"Job\", \"Num_liable\", \"Telephone\", \"Foreign_worker\"\n",
        "]\n",
        "\n",
        "# Convert target: 1 = good credit, 2 = bad credit\n",
        "y = y.replace({1: \"Good\", 2: \"Bad\"})\n",
        "if isinstance(y, pd.DataFrame):\n",
        "    y = y.rename(columns={y.columns[0]: \"Credit_risk\"})\n",
        "else:\n",
        "    y = y.rename(\"Credit_risk\")\n",
        "\n",
        "# Combine features and target\n",
        "df = pd.concat([X, y], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c13e4f3",
      "metadata": {
        "id": "3c13e4f3"
      },
      "source": [
        "### 1. Descriptive Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f72f5a08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f72f5a08",
        "outputId": "8c3a64a3-077e-4ee6-af33-565c186d3067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset overview\n",
            "  Status_checking_account  Duration_month Credit_history Purpose  \\\n",
            "0                     A11               6            A34     A43   \n",
            "1                     A12              48            A32     A43   \n",
            "2                     A14              12            A34     A46   \n",
            "3                     A11              42            A32     A42   \n",
            "4                     A11              24            A33     A40   \n",
            "\n",
            "   Credit_amount Savings_account Employment_since  Installment_rate  \\\n",
            "0           1169             A65              A75                 4   \n",
            "1           5951             A61              A73                 2   \n",
            "2           2096             A61              A74                 2   \n",
            "3           7882             A61              A74                 2   \n",
            "4           4870             A61              A73                 3   \n",
            "\n",
            "  Personal_status_sex Other_debtors_guarantors  ...  Property Age_years  \\\n",
            "0                 A93                     A101  ...      A121        67   \n",
            "1                 A92                     A101  ...      A121        22   \n",
            "2                 A93                     A101  ...      A121        49   \n",
            "3                 A93                     A103  ...      A122        45   \n",
            "4                 A93                     A101  ...      A124        53   \n",
            "\n",
            "   Other_installment_plans Housing Existing_credits   Job Num_liable  \\\n",
            "0                     A143    A152                2  A173          1   \n",
            "1                     A143    A152                1  A173          1   \n",
            "2                     A143    A152                1  A172          2   \n",
            "3                     A143    A153                1  A173          2   \n",
            "4                     A143    A153                2  A173          2   \n",
            "\n",
            "   Telephone Foreign_worker Credit_risk  \n",
            "0       A192           A201        Good  \n",
            "1       A191           A201         Bad  \n",
            "2       A191           A201        Good  \n",
            "3       A191           A201        Good  \n",
            "4       A191           A201         Bad  \n",
            "\n",
            "[5 rows x 21 columns] \n",
            "\n",
            "Shape: (1000, 21) \n",
            "\n",
            "Data types:\n",
            " Status_checking_account     object\n",
            "Duration_month               int64\n",
            "Credit_history              object\n",
            "Purpose                     object\n",
            "Credit_amount                int64\n",
            "Savings_account             object\n",
            "Employment_since            object\n",
            "Installment_rate             int64\n",
            "Personal_status_sex         object\n",
            "Other_debtors_guarantors    object\n",
            "Residence_since              int64\n",
            "Property                    object\n",
            "Age_years                    int64\n",
            "Other_installment_plans     object\n",
            "Housing                     object\n",
            "Existing_credits             int64\n",
            "Job                         object\n",
            "Num_liable                   int64\n",
            "Telephone                   object\n",
            "Foreign_worker              object\n",
            "Credit_risk                 object\n",
            "dtype: object \n",
            "\n",
            "Target distribution:\n",
            " Credit_risk\n",
            "Good    700\n",
            "Bad     300\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "Numeric summary:\n",
            "        Duration_month  Credit_amount  Installment_rate  Residence_since  \\\n",
            "count     1000.000000    1000.000000       1000.000000      1000.000000   \n",
            "mean        20.903000    3271.258000          2.973000         2.845000   \n",
            "std         12.058814    2822.736876          1.118715         1.103718   \n",
            "min          4.000000     250.000000          1.000000         1.000000   \n",
            "25%         12.000000    1365.500000          2.000000         2.000000   \n",
            "50%         18.000000    2319.500000          3.000000         3.000000   \n",
            "75%         24.000000    3972.250000          4.000000         4.000000   \n",
            "max         72.000000   18424.000000          4.000000         4.000000   \n",
            "\n",
            "         Age_years  Existing_credits   Num_liable  \n",
            "count  1000.000000       1000.000000  1000.000000  \n",
            "mean     35.546000          1.407000     1.155000  \n",
            "std      11.375469          0.577654     0.362086  \n",
            "min      19.000000          1.000000     1.000000  \n",
            "25%      27.000000          1.000000     1.000000  \n",
            "50%      33.000000          1.000000     1.000000  \n",
            "75%      42.000000          2.000000     1.000000  \n",
            "max      75.000000          4.000000     2.000000   \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset overview\")\n",
        "print(df.head(), \"\\n\")\n",
        "print(\"Shape:\", df.shape, \"\\n\")\n",
        "print(\"Data types:\\n\", df.dtypes, \"\\n\")\n",
        "print(\"Target distribution:\\n\", df[\"Credit_risk\"].value_counts(), \"\\n\")\n",
        "print(\"Numeric summary:\\n\", df.describe(), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b3a065",
      "metadata": {
        "id": "e7b3a065"
      },
      "source": [
        "#### Descriptive Analysis Summary:\n",
        "\n",
        "The dataset contains 1,000 observations and 21 columns (20 features + 1 target).\n",
        "\n",
        "The target variable Credit_risk has two classes: “Good” (70%) and “Bad” (30%), showing a class imbalance.\n",
        "\n",
        "There are no missing values, meaning the dataset is clean and ready for preprocessing.\n",
        "Most categorical columns are encoded with codes such as A11, A12, etc., corresponding to the original UCI documentation.\n",
        "\n",
        "Numerical columns such as Duration_month, Credit_amount, and Age_years have a wide range of values, suggesting different scales.\n",
        "\n",
        "Feature scaling will therefore be necessary before model training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a9c01de",
      "metadata": {
        "id": "9a9c01de"
      },
      "source": [
        "### 2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f8d02ff6",
      "metadata": {
        "id": "f8d02ff6"
      },
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df.drop(\"Credit_risk\", axis=1)\n",
        "y = df[\"Credit_risk\"]\n",
        "\n",
        "# Encode categorical columns using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "    X[col] = label_encoder.fit_transform(X[col])\n",
        "\n",
        "# Encode target labels (Good = 1, Bad = 0)\n",
        "y = y.map({\"Good\": 1, \"Bad\": 0})\n",
        "\n",
        "# Standardize numeric features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Split dataset into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ee68d1c",
      "metadata": {
        "id": "9ee68d1c"
      },
      "source": [
        "### 3. Problem formalization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dadab7d",
      "metadata": {
        "id": "5dadab7d"
      },
      "source": [
        "The objective of this project is to predict the credit risk of a client based on their financial and personal information.\n",
        "\n",
        "Each observation represents a customer with 20 input features such as:<br>\n",
        "account status,<br>\n",
        "credit history,<br>\n",
        "loan purpose,<br>\n",
        "employment status,<br>\n",
        "age, housing, and others.<br>\n",
        "\n",
        "The target variable (Credit_risk) takes two possible values:\n",
        "\n",
        "\"Good\" → low risk (the customer is likely to repay the credit)<br>\n",
        "\"Bad\" → high risk (the customer may default on payments)\n",
        "\n",
        "Therefore, this is a supervised learning problem, more precisely a binary classification task.\n",
        "\n",
        "Inputs (features): 20 independent variables (mix of categorical and numerical).<br>\n",
        "Output (target): Binary label (Good / Bad).\n",
        "\n",
        "Evaluation metric: Since the classes are slightly imbalanced, we will consider:<br>\n",
        "Accuracy for overall performance.<br>\n",
        "Precision, Recall, and F1-score to better capture class imbalance effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4495e94f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4495e94f",
        "outputId": "412732c2-af1f-4e5e-edb6-d1d5867d0f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of input features: 20\n",
            "Target variable: Credit_risk\n",
            "Unique target classes: ['Good' 'Bad']\n"
          ]
        }
      ],
      "source": [
        "# Define input features (X) and target (y)\n",
        "X = df.drop(\"Credit_risk\", axis=1)\n",
        "y = df[\"Credit_risk\"]\n",
        "\n",
        "print(\"Number of input features:\", X.shape[1])\n",
        "print(\"Target variable:\", y.name)\n",
        "print(\"Unique target classes:\", y.unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07571a54",
      "metadata": {
        "id": "07571a54"
      },
      "source": [
        "### 4. Selection of a Baseline Model and Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4d97889",
      "metadata": {
        "id": "a4d97889"
      },
      "source": [
        "At this stage, we aim to establish a baseline model.\n",
        "\n",
        "Given that our problem is a binary classification (Good / Bad credit risk) and that we have both numerical and categorical features, the chosen baseline model is a Logistic Regression classifier.\n",
        "\n",
        "Reasons for this choice:<br>\n",
        "It is simple and fast to train.<br>\n",
        "It provides interpretable coefficients that indicate feature influence.<br>\n",
        "It performs reasonably well on linearly separable data.\n",
        "\n",
        "The model will be trained on the preprocessed dataset using an 80/20 train-test split.\n",
        "The evaluation will include Accuracy, Precision, Recall, and F1-score to account for the class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9dd56e98",
      "metadata": {
        "id": "9dd56e98"
      },
      "outputs": [],
      "source": [
        "# Baseline model: Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0be2afc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0be2afc7",
        "outputId": "6f991d8b-a417-4f62-ee65-5b8a8c67cf01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Model Evaluation\n",
            "Accuracy: 0.78\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.49      0.57        59\n",
            "           1       0.81      0.90      0.85       141\n",
            "\n",
            "    accuracy                           0.78       200\n",
            "   macro avg       0.74      0.70      0.71       200\n",
            "weighted avg       0.77      0.78      0.77       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "print(\"Baseline Model Evaluation\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0a2abc37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a2abc37",
        "outputId": "1b80a160-21b0-4fe6-e145-b91730a6336c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessed dataset saved as 'german_credit_preprocessed.csv'\n"
          ]
        }
      ],
      "source": [
        "# Save preprocessed dataset\n",
        "df.to_csv(\"german_credit_preprocessed.csv\", index=False, sep=';', encoding='utf-8-sig')\n",
        "print(\"Preprocessed dataset saved as 'german_credit_preprocessed.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1676b62",
      "metadata": {
        "id": "b1676b62"
      },
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5f9387c",
      "metadata": {
        "id": "d5f9387c"
      },
      "source": [
        "The baseline Logistic Regression model achieved a acceptable overall accuracy of around 78%, indicating that the model can reasonably distinguish between good and bad credit risks.<br>\n",
        "However, a closer look at the classification report reveals that the model performs significantly better on the “Good” class than on the “Bad” one.<br>\n",
        "This imbalance suggests that the dataset is not perfectly balanced, which causes the model to favor the majority class (“Good”).\n",
        "\n",
        "To improve performance, especially for detecting high-risk clients, the next steps should include:<br>\n",
        "Applying class balancing techniques, such as SMOTE or class-weight adjustments during training.<br>\n",
        "Exploring more robust models (Random Forest, Gradient Boosting, or XGBoost) that can better capture nonlinear relationships.<br>\n",
        "Feature engineering and selection, to identify the most influential predictors of credit risk.\n",
        "\n",
        "These improvements will allow the model to achieve better generalization and higher reliability for real-world credit risk assessment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WXfx-fQPkTsv",
      "metadata": {
        "id": "WXfx-fQPkTsv"
      },
      "source": [
        "### 5. RandomOverSampler testing for improvements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "V76rVt7gbbMl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V76rVt7gbbMl",
        "outputId": "011779d3-3daa-4af6-e526-48035e9b53ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution before ROS:\n",
            "Credit_risk\n",
            "Good    559\n",
            "Bad     241\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomOverSampler application ...\n",
            "\n",
            "Class distribution after ROS:\n",
            "Credit_risk\n",
            "Bad     559\n",
            "Good    559\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RandomOverSampler evaluation :\n",
            "Accuracy: 0.6950\n",
            "F1-Score (Bad Risk): 0.5960\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.76      0.60        59\n",
            "           1       0.87      0.67      0.76       141\n",
            "\n",
            "    accuracy                           0.69       200\n",
            "   macro avg       0.68      0.71      0.68       200\n",
            "weighted avg       0.76      0.69      0.71       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "print(\"Class distribution before ROS:\")\n",
        "print(y_train.value_counts().rename({1: 'Good', 0: 'Bad'}))\n",
        "\n",
        "#ROS application\n",
        "print(\"\\nRandomOverSampler application ...\")\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nClass distribution after ROS:\")\n",
        "print(y_train_ros.value_counts().rename({1: 'Good', 0: 'Bad'}))\n",
        "\n",
        "# ROS model training\n",
        "model_ros = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_ros.fit(X_train_ros, y_train_ros)\n",
        "y_pred_ros = model_ros.predict(X_test)\n",
        "\n",
        "accuracy_ros = accuracy_score(y_test, y_pred_ros)\n",
        "f1_ros = f1_score(y_test, y_pred_ros, pos_label=0)\n",
        "\n",
        "print(f\"\\nRandomOverSampler evaluation :\")\n",
        "print(f\"Accuracy: {accuracy_ros:.4f}\")\n",
        "print(f\"F1-Score (Bad Risk): {f1_ros:.4f}\\n\")\n",
        "print(classification_report(y_test, y_pred_ros))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b9TRqCbjtY3",
      "metadata": {
        "id": "6b9TRqCbjtY3"
      },
      "source": [
        "Adding a RandomOverSampler to our data improves massively our minority class recall score but it degrades the overall accuracy by almost 10%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca31eee",
      "metadata": {},
      "source": [
        "### SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "693d5b15",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['Credit_risk'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgerman_credit_preprocessed_encoded.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# (si besoin)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# df_encoded[\"Credit_risk\"] = df_encoded[\"Credit_risk\"].map({\"Bad\": 0, \"Good\": 1})\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 2) Définir X et y\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf_encoded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCredit_risk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m y \u001b[38;5;241m=\u001b[39m df_encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCredit_risk\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaille totale du dataset :\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
            "\u001b[1;31mKeyError\u001b[0m: \"['Credit_risk'] not found in axis\""
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Charger le dataset encodé\n",
        "df_encoded = pd.read_csv(\"german_credit_preprocessed_encoded.csv\")\n",
        "\n",
        "# (si besoin)\n",
        "# df_encoded[\"Credit_risk\"] = df_encoded[\"Credit_risk\"].map({\"Bad\": 0, \"Good\": 1})\n",
        "\n",
        "# 2) Définir X et y\n",
        "X = df_encoded.drop(columns=[\"Credit_risk\"])\n",
        "y = df_encoded[\"Credit_risk\"]\n",
        "\n",
        "print(\"Taille totale du dataset :\", X.shape)\n",
        "print(\"Répartition des classes avant split :\", Counter(y))\n",
        "\n",
        "# 3) Split train / test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Taille X_train :\", X_train.shape)\n",
        "print(\"Taille X_test  :\", X_test.shape)\n",
        "print(\"Répartition des classes dans y_train AVANT SMOTE :\", Counter(y_train))\n",
        "print(\"Répartition des classes dans y_test  :\", Counter(y_test))\n",
        "\n",
        "# 4) SMOTE sur le TRAIN uniquement\n",
        "smote = SMOTE(random_state=42, k_neighbors=5)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Taille X_train_res :\", X_train_res.shape)\n",
        "print(\"Répartition des classes dans y_train APRÈS SMOTE :\", Counter(y_train_res))\n",
        "\n",
        "# 5) Modèle Logistic Regression\n",
        "model_smote = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "model_smote.fit(X_train_res, y_train_res)\n",
        "\n",
        "# 6) Évaluation sur le TEST original\n",
        "y_pred_smote = model_smote.predict(X_test)\n",
        "\n",
        "print(\"SMOTE Model Evaluation\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_smote))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_smote))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e7e9653",
      "metadata": {},
      "source": [
        "## Optimisation with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb2ef006",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Modèle de base\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Grille d'hyperparamètres\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  \n",
        "}\n",
        "\n",
        "\n",
        "# Grid Search avec cross-validation\n",
        "grid = GridSearchCV(\n",
        "    estimator=log_reg,\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1',   # ou 'accuracy', 'recall', selon ton projet\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"Meilleurs hyperparamètres trouvés :\", grid.best_params_)\n",
        "print(\"Meilleur score CV :\", grid.best_score_)\n",
        "\n",
        "\n",
        "best_log_reg = grid.best_estimator_\n",
        "best_log_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = best_log_reg.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1-score :\", f1_score(y_test, y_pred))\n",
        "print(\"\\nClassification report :\\n\", classification_report(y_test, y_pred))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
